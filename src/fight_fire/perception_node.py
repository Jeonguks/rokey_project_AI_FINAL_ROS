import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy, DurabilityPolicy
from sensor_msgs.msg import Image, CameraInfo, CompressedImage
from std_msgs.msg import String
from visualization_msgs.msg import Marker
from builtin_interfaces.msg import Duration
from geometry_msgs.msg import PointStamped
from cv_bridge import CvBridge
import cv2
import numpy as np
from ultralytics import YOLO
import tf2_ros
import tf2_geometry_msgs
import time
import json
import message_filters

class PerceptionNode(Node):
    def __init__(self):
        super().__init__('perception_node')
        
        self.namespace = 'robot6' 
        self.model_path = '/home/rokey/datasets/weights/best_amr_v8n_param_add.pt'
        self.camera_frame_id = ""  
        self.last_process_time = 0.0 
        self.camera_intrinsics = None 

        # ---------------------------------------------------------
        # 1. YOLO ëª¨ë¸ ë¡œë“œ
        # ---------------------------------------------------------
        try:
            self.model = YOLO(self.model_path)
            self.get_logger().info(f'âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model_path}')
        except Exception as e:
            self.get_logger().error(f'âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}')

        # ---------------------------------------------------------
        # 2. TF (ì¢Œí‘œ ë³€í™˜ìš©)
        # ---------------------------------------------------------
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ---------------------------------------------------------
        # 3. í†µì‹  ì„¤ì • (Subscriber)
        # ---------------------------------------------------------
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT, 
            history=HistoryPolicy.KEEP_LAST, 
            depth=1,
            durability=DurabilityPolicy.VOLATILE
        )
        
        # RGB & Depth ë™ê¸°í™” êµ¬ë…
        self.rgb_sub = message_filters.Subscriber(
            self, CompressedImage, f'/{self.namespace}/oakd/rgb/image_raw/compressed', qos_profile=qos_profile)
        self.depth_sub = message_filters.Subscriber(
            self, Image, f'/{self.namespace}/oakd/stereo/image_raw', qos_profile=qos_profile)

        self.sync = message_filters.ApproximateTimeSynchronizer(
            [self.rgb_sub, self.depth_sub], queue_size=1, slop=0.5
        )
        self.sync.registerCallback(self.sync_callback)

        # ì¹´ë©”ë¼ ì •ë³´ êµ¬ë…
        self.create_subscription(CameraInfo, f'/{self.namespace}/oakd/rgb/camera_info', self.info_callback, qos_profile)

        # ---------------------------------------------------------
        # 4. í†µì‹  ì„¤ì • (Publisher) - ë¡œì§ ì œê±° í›„ ì •ë³´ë§Œ ì „ë‹¬
        # ---------------------------------------------------------
        # [í•µì‹¬] ê°ì§€ëœ ëª¨ë“  ê°ì²´ì˜ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë¬¶ì–´ì„œ ë³´ëƒ„
        # ì˜ˆ: [{"class": "fire", "dist": 1.5, "cx": 320, "map_x": 2.1, "map_y": 3.5}, ...]
        self.detection_pub = self.create_publisher(String, 'perception/detections', 10)
        
        # ë””ë²„ê¹…ìš© ì´ë¯¸ì§€
        self.debug_pub = self.create_publisher(CompressedImage, f'/{self.namespace}/yolo_debug', 10)
        
        # RViz ì‹œê°í™”ìš© ë§ˆì»¤ (Down ê°ì²´ ë“± í‘œì‹œ)
        self.marker_pub = self.create_publisher(Marker, f'/{self.namespace}/detection_marker', 10)

        self.cv_bridge = CvBridge()
        self.get_logger().info("ğŸ‘€ Perception Node Ready (Pure Sensor Mode)")
        self.get_logger().info("1111111111111111111111")

    def info_callback(self, msg):
        if self.camera_intrinsics is None:
            K = msg.k
            self.camera_intrinsics = {'fx': K[0], 'fy': K[4], 'cx': K[2], 'cy': K[5]}
            self.camera_frame_id = msg.header.frame_id 

    def sync_callback(self, rgb_msg, depth_msg):

        self.get_logger().info(f"sync callback ì§„ì… ---------------------------------")
        current_time = time.time()
        # FPS ì œí•œ (ì‹œìŠ¤í…œ ë¶€í•˜ ë°©ì§€)
        if current_time - self.last_process_time < 0.12: # ì•½ 8 FPS
            return
        self.last_process_time = current_time

        if self.camera_intrinsics is None: return

        try:
            # 1. ì´ë¯¸ì§€ ë””ì½”ë”©
            frame = self.cv_bridge.compressed_imgmsg_to_cv2(rgb_msg, "bgr8")
            if frame is None: return

            # 2. Depth ë””ì½”ë”©
            current_depth = self.cv_bridge.imgmsg_to_cv2(depth_msg, desired_encoding='passthrough')
            depth_h, depth_w = current_depth.shape[:2]

            # 3. YOLO ì¶”ë¡ 
            results = self.model(frame, verbose=False)
            
            detected_objects_list = [] # ë°œí–‰í•  ì •ë³´ ë¦¬ìŠ¤íŠ¸

            for result in results:
                for box in result.boxes:
                    cls_id = int(box.cls[0])
                    conf = float(box.conf[0])
                    class_name = result.names[cls_id]
                    
                    if conf < 0.4: continue # ì‹ ë¢°ë„ ì»·

                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                    
                    # ì‹œê°í™” (ë°•ìŠ¤ ê·¸ë¦¬ê¸°)
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    label = f"{class_name} {conf:.2f}"
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

                    # -----------------------------------------------------
                    # ê±°ë¦¬ ë° ì¢Œí‘œ ê³„ì‚° (Sensor Fusion)
                    # -----------------------------------------------------
                    dist_m = 0.0
                    map_point = None

                    # ë°•ìŠ¤ ì¤‘ì•™ë¶€ì˜ Depth í‰ê· ê°’ ì¶”ì¶œ
                    box_w, box_h = x2 - x1, y2 - y1
                    sx1, sx2 = max(0, int(cx - box_w*0.1)), min(depth_w, int(cx + box_w*0.1))
                    sy1, sy2 = max(0, int(cy - box_h*0.1)), min(depth_h, int(cy + box_h*0.1))

                    depth_roi = current_depth[sy1:sy2, sx1:sx2]
                    valid_depth = depth_roi[depth_roi > 0]

                    if len(valid_depth) > 0:
                        dist_m = float(np.median(valid_depth) / 1000.0) # mm -> meter
                        
                        # 3D ì¢Œí‘œ ë³€í™˜ (Map Frame ê¸°ì¤€)
                        map_point = self.get_map_coordinate(cx, cy, dist_m)
                    
                    # -----------------------------------------------------
                    # ë°ì´í„° íŒ¨í‚¤ì§•
                    # -----------------------------------------------------
                    obj_data = {
                        "class": class_name,
                        "conf": round(conf, 2),
                        "dist": round(dist_m, 3), # ê±°ë¦¬ê°€ ì—†ìœ¼ë©´ 0.0
                        "cx": cx,                 # í™”ë©´ ì¤‘ì‹¬ xì¢Œí‘œ (íšŒì „ ì œì–´ìš©)
                        "cy": cy,
                        "width": box_w,           # ë°•ìŠ¤ í¬ê¸°
                        "height": box_h
                    }

                    # ë§µ ì¢Œí‘œê°€ ìˆë‹¤ë©´ ì¶”ê°€ (ë‚´ë¹„ê²Œì´ì…˜ ëª©í‘œìš©)
                    # if map_point:
                    #     obj_data["map_x"] = round(map_point.point.x, 3)
                    #     obj_data["map_y"] = round(map_point.point.y, 3)
                        
                    #     # RVizì— ë§ˆì»¤ ë„ìš°ê¸° (ì˜µì…˜)
                    #     self.publish_marker(map_point, class_name)

                    detected_objects_list.append(obj_data)

            # 4. ê²°ê³¼ ë°œí–‰ (JSON ë¬¸ìì—´)
            # ë°›ëŠ” ìª½ ì˜ˆì‹œ: data = json.loads(msg.data) -> if data[0]['class'] == 'fire': ...
            if detected_objects_list:
                json_str = json.dumps(detected_objects_list)
                self.detection_pub.publish(String(data=json_str))
                # ë¡œê·¸ëŠ” ë„ˆë¬´ ìì£¼ ì°íˆë©´ ë³´ê¸° í˜ë“œë‹ˆ í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
                # self.get_logger().info(f"Broadcast: {json_str}")

            # 5. ë””ë²„ê·¸ ì´ë¯¸ì§€ ë°œí–‰
            # small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
            # out_msg = self.cv_bridge.cv2_to_compressed_imgmsg(small_frame)
            out_msg = self.cv_bridge.cv2_to_compressed_imgmsg(frame)
            self.debug_pub.publish(out_msg)
            self.get_logger().info("222222222222222222222222222222222")

        except Exception as e:
            self.get_logger().error(f'Processing Error: {e}')

    def get_map_coordinate(self, u, v, dist_m):
        """ì´ë¯¸ì§€ í”½ì…€(u,v)ì™€ ê±°ë¦¬(dist)ë¥¼ ì´ìš©í•´ Map ê¸°ì¤€ ì¢Œí‘œ ê³„ì‚°"""
        if dist_m <= 0: return None

        # 1. ì¹´ë©”ë¼ ì¢Œí‘œê³„ (3D)
        z_cam = dist_m
        x_cam = (u - self.camera_intrinsics['cx']) * z_cam / self.camera_intrinsics['fx']
        y_cam = (v - self.camera_intrinsics['cy']) * z_cam / self.camera_intrinsics['fy']

        point_cam = PointStamped()
        point_cam.header.frame_id = self.camera_frame_id if self.camera_frame_id else "oakd_rgb_camera_optical_frame"
        point_cam.header.stamp = self.get_clock().now().to_msg()
        point_cam.point.x = x_cam
        point_cam.point.y = y_cam
        point_cam.point.z = z_cam

        # 2. TF ë³€í™˜ (Camera -> Map)
        try:
            target_frame = "map"
            transform = self.tf_buffer.lookup_transform(
                target_frame, 
                point_cam.header.frame_id, 
                rclpy.time.Time(seconds=0)
            )
            point_map = tf2_geometry_msgs.do_transform_point(point_cam, transform)
            return point_map
        except Exception:
            return None

    def publish_marker(self, map_point, class_name):
        """RVizì—ì„œ ìœ„ì¹˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆê²Œ ë§ˆì»¤ ë°œí–‰"""
        marker = Marker()
        marker.header.frame_id = "map"
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "detected_objects"
        marker.id = hash(class_name) % 10000 # ê³ ìœ  ID ìƒì„±
        marker.type = Marker.SPHERE
        marker.action = Marker.ADD
        
        marker.pose.position.x = map_point.point.x
        marker.pose.position.y = map_point.point.y
        marker.pose.position.z = 0.5 
        
        marker.scale.x = 0.2; marker.scale.y = 0.2; marker.scale.z = 0.2
        
        # ìƒ‰ìƒ (í´ë˜ìŠ¤ë³„ ë‹¤ë¥´ê²Œ)
        marker.color.a = 0.8
        if class_name == 'fire':
            marker.color.r = 1.0; marker.color.g = 0.0; marker.color.b = 0.0 # ë¹¨ê°•
        elif class_name == 'stand':
            marker.color.r = 0.0; marker.color.g = 1.0; marker.color.b = 0.0 # ì´ˆë¡
        elif class_name == 'down':
            marker.color.r = 0.0; marker.color.g = 0.0; marker.color.b = 1.0 # íŒŒë‘
        else:
            marker.color.r = 1.0; marker.color.g = 1.0; marker.color.b = 0.0 # ë…¸ë‘
            
        self.marker_pub.publish(marker)

def main(args=None):
    rclpy.init(args=args)
    node = PerceptionNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()